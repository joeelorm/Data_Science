{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Tf-idf?\n",
    "\n",
    "Term frequency-inverse document frequency is a numerical statistic used to indicate how important a word is to each document in a collection of documents, or a corpus.\n",
    "\n",
    "When applying tf-idf to a corpus, each word is given a tf-idf score for each document, representing the relevance of that word to the particular document. A higher tf-idf score indicates a term is more important to the corresponding document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          this be a sample sentence  this be my second sentence  \\\n",
      "be                         1.000000                    1.000000   \n",
      "my                         0.000000                    1.287682   \n",
      "sample                     1.693147                    0.000000   \n",
      "second                     0.000000                    1.693147   \n",
      "sentence                   1.000000                    1.000000   \n",
      "third                      0.000000                    0.000000   \n",
      "this                       1.000000                    1.000000   \n",
      "\n",
      "          be this my third sentence  \n",
      "be                         1.000000  \n",
      "my                         1.287682  \n",
      "sample                     0.000000  \n",
      "second                     0.000000  \n",
      "sentence                   1.000000  \n",
      "third                      1.693147  \n",
      "this                       1.000000  \n"
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocess_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# sample documents\n",
    "document_1 = \"This is a sample sentence!\"\n",
    "document_2 = \"This is my second sentence.\"\n",
    "document_3 = \"Is this my third sentence?\"\n",
    "\n",
    "# corpus of documents\n",
    "corpus = [document_1, document_2, document_3]\n",
    "\n",
    "# preprocess documents\n",
    "processed_corpus = [preprocess_text(doc) for doc in corpus]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tf_idf_scores = vectorizer.fit_transform(processed_corpus)\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in processed_corpus]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "df_tf_idf = pd.DataFrame(tf_idf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         data science be great  \\\n",
      "be                    1.287682   \n",
      "can                   0.000000   \n",
      "data                  1.287682   \n",
      "find                  0.000000   \n",
      "from                  0.000000   \n",
      "great                 1.287682   \n",
      "insight               0.000000   \n",
      "learn                 0.000000   \n",
      "machine               0.000000   \n",
      "science               1.287682   \n",
      "skill                 0.000000   \n",
      "the                   0.000000   \n",
      "too                   0.000000   \n",
      "with                  0.000000   \n",
      "\n",
      "         i can find insight with the skill from data science  \\\n",
      "be                                                0.000000     \n",
      "can                                               1.693147     \n",
      "data                                              1.287682     \n",
      "find                                              1.693147     \n",
      "from                                              1.693147     \n",
      "great                                             0.000000     \n",
      "insight                                           1.693147     \n",
      "learn                                             0.000000     \n",
      "machine                                           0.000000     \n",
      "science                                           1.287682     \n",
      "skill                                             1.693147     \n",
      "the                                               1.693147     \n",
      "too                                               0.000000     \n",
      "with                                              1.693147     \n",
      "\n",
      "         machine learn be great too  \n",
      "be                         1.287682  \n",
      "can                        0.000000  \n",
      "data                       0.000000  \n",
      "find                       0.000000  \n",
      "from                       0.000000  \n",
      "great                      1.287682  \n",
      "insight                    0.000000  \n",
      "learn                      1.693147  \n",
      "machine                    1.693147  \n",
      "science                    0.000000  \n",
      "skill                      0.000000  \n",
      "the                        0.000000  \n",
      "too                        1.693147  \n",
      "with                       0.000000  \n"
     ]
    }
   ],
   "source": [
    "# sample documents\n",
    "document_1 = \"Data Science is great!\"\n",
    "document_2 = \"I can find insights with the skills from Data Science.\"\n",
    "document_3 = \"Machine Learning is great too?\"\n",
    "\n",
    "# corpus of documents\n",
    "corpus = [document_1, document_2, document_3]\n",
    "\n",
    "# preprocess documents\n",
    "processed_corpus = [preprocess_text(doc) for doc in corpus]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tf_idf_scores = vectorizer.fit_transform(processed_corpus)\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in processed_corpus]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "df_tf_idf = pd.DataFrame(tf_idf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term Frequency\n",
      "agonize                  1\n",
      "all                      1\n",
      "and                      1\n",
      "be                       1\n",
      "break                    1\n",
      "by                       1\n",
      "can                      1\n",
      "clear                    2\n",
      "comprehend               1\n",
      "count                    1\n",
      "day                      1\n",
      "defeat                   1\n",
      "definition               1\n",
      "die                      1\n",
      "distant                  1\n",
      "ear                      1\n",
      "er                       1\n",
      "flag                     1\n",
      "forbid                   1\n",
      "he                       1\n",
      "host                     1\n",
      "ne                       1\n",
      "nectar                   1\n",
      "need                     1\n",
      "not                      1\n",
      "of                       3\n",
      "on                       1\n",
      "one                      1\n",
      "purple                   1\n",
      "require                  1\n",
      "so                       1\n",
      "sorest                   1\n",
      "strain                   1\n",
      "succeed                  1\n",
      "success                  1\n",
      "sweet                    1\n",
      "take                     1\n",
      "tell                     1\n",
      "the                      4\n",
      "those                    1\n",
      "to                       2\n",
      "triumph                  1\n",
      "victory                  1\n",
      "who                      2\n",
      "whose                    1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "poem = '''\n",
    "Success is counted sweetest\n",
    "By those who ne'er succeed.\n",
    "To comprehend a nectar\n",
    "Requires sorest need.\n",
    "\n",
    "Not one of all the purple host\n",
    "Who took the flag to-day\n",
    "Can tell the definition,\n",
    "So clear, of victory,\n",
    "\n",
    "As he, defeated, dying,\n",
    "On whose forbidden ear\n",
    "The distant strains of triumph\n",
    "Break, agonized and clear!'''\n",
    "\n",
    "# define clear_count:\n",
    "clear_count = 2\n",
    "\n",
    "# preprocess text\n",
    "processed_poem = preprocess_text(poem)\n",
    "\n",
    "# initialize and fit CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "term_frequencies = vectorizer.fit_transform([processed_poem])\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# create pandas DataFrame with term frequencies\n",
    "try:\n",
    "  df_term_frequencies = pd.DataFrame(term_frequencies.T.todense(), index=feature_names, columns=['Term Frequency'])\n",
    "  print(df_term_frequencies)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Poem 1  Poem 2  Poem 3  Poem 4  Poem 5  Poem 6\n",
      "abash         0       0       0       0       1       0\n",
      "across        0       0       0       1       0       0\n",
      "admire        0       0       1       0       0       0\n",
      "again         0       0       0       1       0       0\n",
      "agonize       1       0       0       0       0       0\n",
      "...         ...     ...     ...     ...     ...     ...\n",
      "word          0       0       0       0       1       0\n",
      "wreck         0       0       0       1       0       0\n",
      "yet           0       0       0       0       1       0\n",
      "you           0       0       3       0       0       0\n",
      "your          0       0       1       0       0       0\n",
      "\n",
      "[173 rows x 6 columns]\n",
      "         Inverse Document Frequency\n",
      "abash                      2.252763\n",
      "across                     2.252763\n",
      "admire                     2.252763\n",
      "again                      2.252763\n",
      "agonize                    2.252763\n",
      "...                             ...\n",
      "word                       2.252763\n",
      "wreck                      2.252763\n",
      "yet                        2.252763\n",
      "you                        2.252763\n",
      "your                       2.252763\n",
      "\n",
      "[173 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from term_frequency import term_frequencies, feature_names, df_term_frequencies\n",
    "\n",
    "# display term-document matrix of term frequencies\n",
    "print(df_term_frequencies)\n",
    "\n",
    "# initialize and fit TfidfTransformer\n",
    "transformer = TfidfTransformer(norm = None)\n",
    "\n",
    "transformer.fit(term_frequencies)\n",
    "idf_values = transformer.idf_\n",
    "\n",
    "\n",
    "# create pandas DataFrame with inverse document frequencies\n",
    "try:\n",
    "  df_idf = pd.DataFrame(idf_values, index = feature_names, columns=['Inverse Document Frequency'])\n",
    "  print(df_idf)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Poem 1  Poem 2    Poem 3    Poem 4    Poem 5  Poem 6\n",
      "abash    0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "across   0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "admire   0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "again    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "agonize  2.252763     0.0  0.000000  0.000000  0.000000     0.0\n",
      "...           ...     ...       ...       ...       ...     ...\n",
      "word     0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "wreck    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "yet      0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "you      0.000000     0.0  6.758289  0.000000  0.000000     0.0\n",
      "your     0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from poems import poems\n",
    "# preprocess documents\n",
    "processed_poems = [preprocess_text(poem) for poem in poems]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_poems)\n",
    "\n",
    "\n",
    "# get vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# get corpus index\n",
    "corpus_index = [f\"Poem {i+1}\" for i in range(len(poems))]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=corpus_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Bag-Of-Words to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Poem 1  Poem 2  Poem 3  Poem 4  Poem 5  Poem 6\n",
      "abash         0       0       0       0       1       0\n",
      "across        0       0       0       1       0       0\n",
      "admire        0       0       1       0       0       0\n",
      "again         0       0       0       1       0       0\n",
      "agonize       1       0       0       0       0       0\n",
      "...         ...     ...     ...     ...     ...     ...\n",
      "word          0       0       0       0       1       0\n",
      "wreck         0       0       0       1       0       0\n",
      "yet           0       0       0       0       1       0\n",
      "you           0       0       3       0       0       0\n",
      "your          0       0       1       0       0       0\n",
      "\n",
      "[173 rows x 6 columns]\n",
      "           Poem 1  Poem 2    Poem 3    Poem 4    Poem 5  Poem 6\n",
      "abash    0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "across   0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "admire   0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "again    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "agonize  2.252763     0.0  0.000000  0.000000  0.000000     0.0\n",
      "...           ...     ...       ...       ...       ...     ...\n",
      "word     0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "wreck    0.000000     0.0  0.000000  2.252763  0.000000     0.0\n",
      "yet      0.000000     0.0  0.000000  0.000000  2.252763     0.0\n",
      "you      0.000000     0.0  6.758289  0.000000  0.000000     0.0\n",
      "your     0.000000     0.0  2.252763  0.000000  0.000000     0.0\n",
      "\n",
      "[173 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from termfrequency import bow_matrix, feature_names, df_bag_of_words, corpus_index\n",
    "\n",
    "# display term-document matrix of term frequencies (bag-of-words)\n",
    "print(df_bag_of_words)\n",
    "\n",
    "# initialize and fit TfidfTransformer, transform bag-of-words matrix\n",
    "transformer = TfidfTransformer(norm = None)\n",
    "tfidf_scores = transformer.fit_transform(bow_matrix)\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index = feature_names, columns=corpus_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a midnight dreary, while I pondered, weak and weary,\n",
      " Over many a quaint and curious volume of forgotten lore,\n",
      " While I nodded, nearly napping, suddenly there came a tapping,\n",
      " As of some one gently rapping, rapping at my chamber door\n",
      "        Stanza 1  Stanza 2  Stanza 3  Stanza 4  Stanza 5   Stanza 6  Stanza 7  \\\n",
      "above        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "adore        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "again        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "agree        0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "ah           0.0       0.0  3.079442       0.0       0.0   0.000000       0.0   \n",
      "...          ...       ...       ...       ...       ...        ...       ...   \n",
      "wretch       0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "yet          0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "yore         0.0       0.0  0.000000       0.0       0.0   0.000000       0.0   \n",
      "you          0.0       0.0  0.000000       0.0       0.0  10.454720       0.0   \n",
      "your         0.0       0.0  0.000000       0.0       0.0   3.484907       0.0   \n",
      "\n",
      "        Stanza 8  Stanza 9  Stanza 10  ...  Stanza 14  Stanza 15  Stanza 16  \\\n",
      "above   0.000000  4.772589        0.0  ...        0.0        0.0   0.000000   \n",
      "adore   0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "again   3.484907  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "agree   0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "ah      0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "...          ...       ...        ...  ...        ...        ...        ...   \n",
      "wretch  0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "yet     0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "yore    0.000000  3.079442        0.0  ...        0.0        0.0   6.158883   \n",
      "you     0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "your    0.000000  0.000000        0.0  ...        0.0        0.0   0.000000   \n",
      "\n",
      "        Stanza 17  Stanza 18  Stanza 19  Stanza 20  Stanza 21  Stanza 22  \\\n",
      "above    0.000000   0.000000   0.000000   2.386294        0.0   2.386294   \n",
      "adore    0.000000   0.000000   0.000000   3.484907        0.0   0.000000   \n",
      "again    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "agree    0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "ah       3.079442   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "wretch   0.000000   3.484907   0.000000   0.000000        0.0   0.000000   \n",
      "yet      0.000000   0.000000   3.079442   0.000000        0.0   0.000000   \n",
      "yore     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "you      0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "your     0.000000   0.000000   0.000000   0.000000        0.0   0.000000   \n",
      "\n",
      "        Stanza 23  \n",
      "above    2.386294  \n",
      "adore    0.000000  \n",
      "again    0.000000  \n",
      "agree    0.000000  \n",
      "ah       0.000000  \n",
      "...           ...  \n",
      "wretch   0.000000  \n",
      "yet      0.000000  \n",
      "yore     0.000000  \n",
      "you      0.000000  \n",
      "your     0.000000  \n",
      "\n",
      "[413 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from raven import the_raven_stanzas\n",
    "from preprocessing import preprocess_text\n",
    "\n",
    "# view first stanza\n",
    "print(the_raven_stanzas[0])\n",
    "\n",
    "\n",
    "# preprocess documents\n",
    "processed_stanzas = [preprocess_text(stanza) for stanza in the_raven_stanzas]\n",
    "\n",
    "# initialize and fit TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm = None)\n",
    "tfidf_scores = vectorizer.fit_transform(processed_stanzas)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "# get vocabulary of terms\n",
    "\n",
    "\n",
    "# get stanza index\n",
    "stanza_index = [f\"Stanza {i+1}\" for i in range(len(the_raven_stanzas))]\n",
    "\n",
    "# create pandas DataFrame with tf-idf scores\n",
    "try:\n",
    "  df_tf_idf = pd.DataFrame(tfidf_scores.T.todense(), index=feature_names, columns=stanza_index)\n",
    "  print(df_tf_idf)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
