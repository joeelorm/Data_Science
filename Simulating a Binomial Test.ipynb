{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial tests are useful for comparing the frequency of some outcome in a sample to the expected probability of that outcome. For example, if we expect 90% of ticketed passengers to show up for their flight but only 80 of 100 ticketed passengers actually show up, we could use a binomial test to understand whether 80 is significantly different from 90.\n",
    "\n",
    "Binomial tests are similar to one-sample t-tests in that they test a sample statistic against some population-level expectation. The difference is that:\n",
    "\n",
    "- binomial tests are used for binary categorical data to compare a sample frequency to an expected population-level probability\n",
    "\n",
    "- one-sample t-tests are used for quantitative data to compare a sample mean to an expected population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will walk through the process of using a binomial test to analyze data from a hypothetical online company, Live-it-LIVE.com — a website that sells all the necessary props and costumes to recreate iconic movie scenes at home!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp purchase                       item\n",
      "0    2020-01-17 17:23:06        y  cue cards - love actually\n",
      "1    2020-01-25 17:09:39        n                        NaN\n",
      "2    2020-01-25 05:22:01        n                        NaN\n",
      "3    2020-01-18 04:33:40        y      t-rex - jurassic park\n",
      "4    2020-01-24 17:24:52        n                        NaN\n",
      "..                   ...      ...                        ...\n",
      "495  2020-01-16 08:40:02        n                        NaN\n",
      "496  2020-01-09 21:11:19        n                        NaN\n",
      "497  2020-01-31 08:54:51        n                        NaN\n",
      "498  2020-01-21 19:35:03        n                        NaN\n",
      "499  2020-01-31 09:48:43        n                        NaN\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "monthly_report = pd.read_csv('../Datasets/monthly_report.csv')\n",
    "print(monthly_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the purchase column tells us whether a purchase was made; if so, the item that was purchased is listed in the item column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing the Sample\n",
    "The marketing department at Live-it-LIVE reports that, during this time of year, about 10% of visitors to Live-it-LIVE.com make a purchase.\n",
    "\n",
    "The monthly report shows every visitor to the site and whether or not they made a purchase. The checkout page had a small bug this month, so the business department wants to know whether the purchase rate dipped below expectation. They’ve asked us to investigate this question.\n",
    "\n",
    "In order to run a hypothesis test to address this, we’ll first need to know two things from the data:\n",
    "\n",
    "The number of people who visited the website\n",
    "The number of people who made a purchase on the website\n",
    "Assuming each row of our dataset represents a unique site visitor, we can calculate the number of people who visited the website by finding the number of rows in the data frame. We can then find the number who made a purchase by using a conditional statement to add up the total number of rows where a purchase was made.\n",
    "\n",
    "For example, suppose that the dataset candy contains a column named chocolate with 'yes' recorded for every candy that has chocolate in it and 'no' otherwise. The following code calculates the sample size (the number of candies) and the number of those candies that contain chocolate:\n",
    "\n",
    "sample size (number of rows): \n",
    "`samp_size = len(candy)`\n",
    " \n",
    "number with chocolate: \n",
    "`total_with_chocolate = np.sum(candy.chocolate == 'yes')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#calculate and print sample_size:\n",
    "sample_size = len(monthly_report)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "#calculate and print num_purchased:\n",
    "num_purchased = np.sum(monthly_report['purchase'] == 'y')\n",
    "print(num_purchased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating Randomness\n",
    "In the cell above, we calculated that there were 500 site visitors to live-it-LIVE.com this month and 41 of them made a purchase. In comparison, if each of the 500 visitors had a 10% chance of making a purchase, we would expect around 50 of those visitors to buy something. Is 41 different enough from 50 that we should question whether this months’ site visitors really had a 10% chance of making a purchase?\n",
    "\n",
    "To conceptualize why our expectation (50) and observation (41) might not be equal — EVEN IF there was no dip in the purchase probability — let’s turn to a common probability example: flipping a fair coin. We can simulate a coin flip in Python using the numpy.random.choice() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heads']\n"
     ]
    }
   ],
   "source": [
    "#An example\n",
    "flip = np.random.choice(['heads', 'tails'], size=1, p=[0.5, 0.5])\n",
    "print(flip) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this code (or flip a real coin) a few times, we’ll find that — just like we can’t know ahead of time whether any single visitor to Live-it-LIVE.com will make a purchase — we can’t predict the outcome of any individual coin flip.\n",
    "\n",
    "If we flip a fair coin 10 times in a row, we expect about 5 of those coins to come up heads (50%). We can simulate this in python by changing the size parameter of numpy.random.choice():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tails' 'tails' 'heads' 'heads' 'tails' 'heads' 'heads' 'heads' 'heads'\n",
      " 'heads']\n"
     ]
    }
   ],
   "source": [
    "flip = np.random.choice(['heads', 'tails'], size=10, p=[0.5, 0.5])\n",
    "print(flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n']\n"
     ]
    }
   ],
   "source": [
    "#simulate one visitor:\n",
    "one_visitor = np.random.choice(['n', 'y'], p = [0.9 , 0.1], size = 1)\n",
    "print(one_visitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'y' 'y' 'n' 'n' 'y' 'n' 'y' 'y' 'n' 'n' 'y' 'n' 'y'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'y' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'y' 'y' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n'\n",
      " 'n' 'y' 'n' 'y' 'n' 'n' 'y' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y'\n",
      " 'n' 'n' 'y' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'y' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'y' 'n' 'y'\n",
      " 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'y'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n'\n",
      " 'y' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'y' 'n'\n",
      " 'n' 'n' 'y' 'n' 'y' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'y']\n"
     ]
    }
   ],
   "source": [
    "#simulate 500 visitors:\n",
    "simulated_monthly_visitors = np.random.choice(['n', 'y'], p = [0.9, 0.1], size = 500)\n",
    "print(simulated_monthly_visitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating the Null Distribution I\n",
    "The first step in running a hypothesis test is to form a null hypothesis. For the question of whether the purchase rate at Live-it-LIVE.com was different from 10% this month, the null hypothesis describes a world in which the true probability of a visitor making a purchase was exactly 10%, but by random chance, we observed that only 41 visitors (8.2%) made a purchase.\n",
    "\n",
    "Let’s return to the coin flip example from the previous exercise. We can simulate 10 coin flips and print out the number of those flips that came up heads using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "flips = np.random.choice(['heads', 'tails'], size=10, p=[0.5, 0.5])\n",
    "num_heads = np.sum(flips == 'heads')\n",
    "print(num_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this code a few times, we’ll likely see different results each time. This will give us get a sense for the range in the number of heads that could occur by random chance, even if the coin is fair. We’re more likely to see numbers like four, five, or six, but maybe we’ll see something more extreme every once in a while — ten heads in a row, or even zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "#simulate 500 visitors:\n",
    "simulated_monthly_visitors = np.random.choice(['y', 'n'], size=500, p=[0.1, 0.9])\n",
    "\n",
    "#calculate the number of simulated visitors who made a purchase:\n",
    "num_purchased = np.sum(simulated_monthly_visitors == 'y')\n",
    "print(num_purchased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating the Null Distribution II\n",
    "In the last cell, we simulated a random sample of 500 visitors, where each visitor had a 10% chance of making a purchase. When we pressed “Run” a few times, we saw that the number of purchases varied from sample to sample, but was around 50.\n",
    "\n",
    "Similarly, we simulated a single random sample of 10 coin flips, where each flip had a 50% chance of coming up heads. We saw that the number of simulated heads was not necessarily 5, but somewhere around 5.\n",
    "\n",
    "By running the same simulated experiment many times, we can get a sense for how much a particular outcome (like the number of purchases, or heads) varies by random chance. Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for i in range(10000): \n",
    "    flips = np.random.choice(['heads', 'tails'], size=10, p=[0.5, 0.5])\n",
    "    num_heads = np.sum(flips == 'heads')\n",
    "    outcomes.append(num_heads)\n",
    "#print(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code chunk, we’ve done the following:\n",
    "\n",
    "- initialized an empty list named outcomes to store the number of ‘heads’ from simulated samples of coin flips\n",
    "- set up a for-loop to repeat the steps below 10000 times:\n",
    "\n",
    "  -flip a fair coin 10 times\n",
    "  \n",
    "  -calculate the number of those 10 flips that came up heads\n",
    "  \n",
    "  -append that number onto outcomes\n",
    "  \n",
    "Note that 10000 is an arbitrarily chosen large number — it’s big enough that it will yield almost all possible outcomes of our experiment, and small enough that the simulation still runs quickly. From inspecting the output, we can see that the number of ‘heads’ varied between 0 and 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "min_heads = np.min(outcomes) \n",
    "print(min_heads) \n",
    " \n",
    "max_heads = np.max(outcomes)\n",
    "print(max_heads) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if we flip a fair coin 10 times, we could observe anywhere between 0 and 10 heads by random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "null_outcomes = []\n",
    "\n",
    "#start for loop here:\n",
    "for i in range(10000):\n",
    "  simulated_monthly_visitors = np.random.choice(['y', 'n'], size=500, p=[0.1, 0.9])\n",
    "  num_purchased = np.sum(simulated_monthly_visitors == 'y')\n",
    "  null_outcomes.append(num_purchased)\n",
    "\n",
    "\n",
    "#calculate the minimum and maximum values in null_outcomes here:\n",
    "null_min = np.min(null_outcomes)\n",
    "null_max = np.max(null_outcomes)\n",
    "print(null_min)\n",
    "print(null_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the Null Distribution\n",
    "In the previous cell, we simulated 10000 different samples of 500 visitors, where each visitor had a 10% chance of making a purchase, and calculated the number of purchases per sample. Upon further inspection, we saw that those numbers ranged from around 25 to 75. This is useful information, but we can learn even more from inspecting the full distribution.\n",
    "\n",
    "For example, recall our 10000 coin flip experiments: for each experiment, we flipped a fair coin 10 times and recorded the number of heads in a list named outcomes. We can plot a histogram of outcomes using matplotlib.pyplot.hist(). We can also add a vertical line at any x-value using matplotlib.pyplot.axvline():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(outcomes, edgecolor = 'black')\n",
    "plt.axvline(2, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram shows us that, over 10000 experiments, we observed as few as 0 and as many as 10 heads out of 10 flips. However, we were most likely to observe around 4-6 heads. It would be unlikely to observe only 2 heads (where the vertical red line is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the histogram of the null outcomes:\n",
    "plt.hist(null_outcomes, edgecolor = 'black')\n",
    "\n",
    "plt.axvline(41, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41 purchases is somewhat likely to occur based on this null distribution. It’s not in the middle of the distribution, where there’s the most density, but it’s also not way out in the tails (which would mean it is very unlikely)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals\n",
    "So far, we’ve inspected the null distribution and calculated the minimum and maximum values. While the number of purchases in each simulated sample ranged roughly from 25 to 75 by random chance, upon further inspection of the distribution, we saw that those extreme values happened very rarely.\n",
    "\n",
    "By reporting an interval covering 95% of the values instead of the full range, we can say something like: “we are 95% confident that, if each visitor has a 10% chance of making a purchase, a random sample of 500 visitors will make between 37 and 63 purchases.” We can use the np.percentile() function to calculate this 95% interval as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37., 63.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(null_outcomes, [2.5,97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the 2.5th and 97.5th percentiles so that exactly 5% of the data falls outside those percentiles (2.5% above the 97.5th percentile, and 2.5% below the 2.5th percentile). This leaves us with a range covering 95% of the data.\n",
    "\n",
    "If our observed statistic falls outside this interval, then we can conclude it is unlikely that the null hypothesis is true. In this example, because 41 falls within the 95% interval (37 - 63), it is still reasonably likely that we observed a lower purchase rate by random chance, even though the null hypothesis was true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39. 61.]\n"
     ]
    }
   ],
   "source": [
    "#calculate the 90% interval here:\n",
    "null_90CI = np.percentile(null_outcomes, [5, 95])\n",
    "print(null_90CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a One-Sided P-Value\n",
    "P-value calculations and interpretations depend on the alternative hypothesis of a test, a description of the difference from expectation that we are interested in.\n",
    "\n",
    "For example, let’s return to the 10-coin-flip example from earlier. Suppose that we flipped a coin 10 times and observed only 2 heads. We might run a hypothesis test with the following null and alternative hypotheses:\n",
    "\n",
    "- Null: the probability of heads is 0.5\n",
    "- Alternative: the probability of heads is less than 0.5\n",
    "\n",
    "This hypothesis test asks the question: IF the probability of heads is 0.5, what’s the probability of observing 2 or fewer heads among a single sample of 10 coin flips?\n",
    "\n",
    "Earlier, we used a for-loop to repeatedly (10000 times!) flip a fair coin 10 times, and store the number of heads (for each set of 10 flips) in a list named outcomes. The probability of observing 2 or fewer heads among 10 coin flips is approximately equal to the proportion of those 10000 experiments where we observed 0, 1, or 2 heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0512\n"
     ]
    }
   ],
   "source": [
    "outcomes = np.array(outcomes)\n",
    "p_value = np.sum(outcomes <= 2)/len(outcomes) \n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimated that the probability of observing 2 or fewer heads is about 0.059 (5.9%). This probability (0.059) is referred to as a one-sided p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0985\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value here:\n",
    "null_outcomes = np.array(null_outcomes)\n",
    "p_value = np.sum(null_outcomes <= 41)/len(null_outcomes)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a Two-Sided P-Value\n",
    "In the previous cell, we calculated a one-sided p-value. In this exercise, we’ll estimate a p-value for a 2-sided test, which is the default setting for many functions in Python (and other languages, like R!).\n",
    "\n",
    "In our 10-coin-flip experiment, remember that we observed 2 heads, which is 3 less than the expected value of 5 (50% of 10) if the null hypothesis is true. The two sided test focuses on the number of heads being three different from expectation, rather than just less than. The hypothesis test now asks the following question:\n",
    "\n",
    "Suppose that the true probability of heads is 50%. What is the probability of observing either two or fewer heads OR eight or more heads? (Note that two and eight are both three away from five). \n",
    "\n",
    "This proportion can be calculated in Python as follows. Note that the `|` symbol is similar to `'or'`, but works for comparing multiple values at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1066\n"
     ]
    }
   ],
   "source": [
    "outcomes = np.array(outcomes)\n",
    "p_value = np.sum((outcomes <= 2) | (outcomes >= 8))/len(outcomes)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use null_outcomes to calculate the p-value for a two-sided test (alternative hypothesis is that the purchase probability was DIFFERENT FROM 10%). Remember that, if the purchase rate is 10%, we expect 50 of the 500 visitors to make a purchase.\n",
    "\n",
    "In other words, calculate the proportion of values in null_outcomes that are less than or equal to 41 (the number of purchases we observed in our sample, which is 9 fewer than 50) OR greater than or equal to 59 (which is 9 purchases more than 50). Save this number as a variable named p_value and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2006\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value here:\n",
    "null_outcomes = np.array(null_outcomes)\n",
    "p_value = np.sum((null_outcomes <= 41) | (null_outcomes >= 59))/len(null_outcomes)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing a Binomial Test Function\n",
    "So far, we’ve conducted a simulated binomial hypothesis test for Live-it-LIVE.com. In this exercise, we’ll use our code from the previous exercises to write our own binomial test function. Our function will use simulation, so it will estimate (albeit fairly accurately) the same p-values we would get using much more complex mathematical equations.\n",
    "\n",
    "A function has been outlined for you in script.py which contains the code that we used for Live_it_LIVE inside a function named simulation_binomial_test(). Your goal in the next few exercises will be to edit this function so that it takes in any values for the following:\n",
    "\n",
    "- The observed sample statistic (eg., 41 purchases)\n",
    "- The sample size (eg., 500 visitors)\n",
    "- The null probability of success (eg., 0.10 probability of a purchase)\n",
    "\n",
    "The function should return a p-value for a one-sided test where the alternative hypothesis is that the true probability of success is LESS THAN the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_binomial_test(observed_successes, n, p):\n",
    "  #initialize null_outcomes\n",
    "  null_outcomes = []\n",
    "  \n",
    "  #generate the simulated null distribution\n",
    "  for i in range(10000):\n",
    "    simulated_monthly_visitors = np.random.choice(['y', 'n'], size=500, p=[p, 1-p])\n",
    "    num_purchased = np.sum(simulated_monthly_visitors == 'y')\n",
    "    null_outcomes.append(num_purchased)\n",
    "\n",
    "  #calculate a 1-sided p-value\n",
    "  null_outcomes = np.array(null_outcomes)\n",
    "  p_value = np.sum(null_outcomes <= observed_successes)/n \n",
    "  \n",
    "  #return the p-value\n",
    "  return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation p-value:  5.13\n"
     ]
    }
   ],
   "source": [
    "p_value1 = simulation_binomial_test(45, 500, .1)\n",
    "print(\"simulation p-value: \", p_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binom_test p-value:  0.25468926056232155\n"
     ]
    }
   ],
   "source": [
    "p_value2 = binom_test(45, 500, .1, alternative = 'less')\n",
    "print(\"binom_test p-value: \", p_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binomial Testing with SciPy\n",
    "More formally, the binomial distribution describes the number of expected “successes” in an experiment with some number of “trials”. In the example you just worked through, the experiment consisted of 500 people visiting Live-it-LIVE.com. For each of those trials (visitors), we expected a 10% chance of a purchase (success), but observed only 41 successes (less than 10%).\n",
    "\n",
    "SciPy has a function called binom_test(), which performs a binomial test for you. The default alternative hypothesis for the binom_test() function is two-sided, but this can be changed using the alternative parameter (eg., alternative = 'less' will run a one-sided lower tail test).\n",
    "\n",
    "binom_test() requires three inputs, the number of observed successes, the number of total trials, and an expected probability of success. For example, with 10 flips of a fair coin (trials), the expected probability of heads is 0.5. Let’s imagine we get 2 heads (observed successes) in 10 flips. Is the coin weighted? The function call for this binomial test would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10937500000000003\n"
     ]
    }
   ],
   "source": [
    "p_value = binom_test(2, n=10, p=0.5)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that IF the true probability of heads is 0.5, the probability of observing 2 or fewer heads OR 8 or more heads is 0.109 (10.9%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20456397700678308\n",
      "0.1001135269756488\n"
     ]
    }
   ],
   "source": [
    "# calculate p_value_2sided here:\n",
    "p_value_2sided = binom_test(41, n = 500, p = 0.10)\n",
    "print(p_value_2sided)\n",
    "# calculate p_value_1sided here:\n",
    "p_value_1sided = binom_test(41, n = 500, p = 0.10, alternative = 'less')\n",
    "print(p_value_1sided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, here are some of the things you’ve learned about hypothesis tests in general:\n",
    "\n",
    "- All hypothesis tests start with a null and alternative hypothesis\n",
    "\n",
    "- Outcomes of a hypothesis test that might be reported include:\n",
    "\n",
    "  -confidence intervals\n",
    "  \n",
    "  -p-values\n",
    "  \n",
    "  \n",
    "- A hypothesis test can be simulated by:\n",
    "\n",
    "  -taking repeated random samples where the null hypothesis is assumed to be true\n",
    "  \n",
    "  -using those simulated samples to generate a null distribution\n",
    "  \n",
    "  -comparing an observed sample statistic to that null distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower tail one-sided test:\n",
      "simulation p-value:  0.2576\n",
      "binom_test p-value:  0.25468926056232155\n",
      "upper tail one-sided test:\n",
      "simulation p-value:  0.3594\n",
      "binom_test p-value:  0.3483811994999115\n",
      "two-sided test:\n",
      "simulation p-value:  0.2625\n",
      "binom_test p-value:  0.26313834687316334\n"
     ]
    }
   ],
   "source": [
    "def simulation_binomial_test(observed_successes, n, p, alternative_hypothesis):\n",
    "  #initialize null_outcomes\n",
    "  null_outcomes = []\n",
    "  \n",
    "  #generate the simulated null distribution\n",
    "  for i in range(10000):\n",
    "    simulated_monthly_visitors = np.random.choice(['y', 'n'], size=n, p=[p, 1-p])\n",
    "    num_purchased = np.sum(simulated_monthly_visitors == 'y')\n",
    "    null_outcomes.append(num_purchased)\n",
    "\n",
    "  null_outcomes = np.array(null_outcomes)\n",
    "\n",
    "  if alternative_hypothesis == 'less':\n",
    "    p_value = np.sum(null_outcomes <= observed_successes)/len(null_outcomes) \n",
    "  elif alternative_hypothesis == 'greater':\n",
    "    p_value = np.sum(null_outcomes >= observed_successes)/len(null_outcomes)\n",
    "  else:\n",
    "    difference = np.abs(p*n - observed_successes)\n",
    "    upper = p*n + difference\n",
    "    lower = p*n - difference\n",
    "    p_value = np.sum((null_outcomes >= upper) | (null_outcomes <= lower))/len(null_outcomes)\n",
    "  \n",
    "  #return the p-value\n",
    "  return p_value\n",
    "\n",
    "#Test your function:\n",
    "print('lower tail one-sided test:')\n",
    "p_value1 = simulation_binomial_test(45, 500, .1, alternative_hypothesis = 'less')\n",
    "print(\"simulation p-value: \", p_value1)\n",
    "\n",
    "p_value2 = binom_test(45, 500, .1, alternative = 'less')\n",
    "print(\"binom_test p-value: \", p_value2)\n",
    "\n",
    "print('upper tail one-sided test:')\n",
    "p_value1 = simulation_binomial_test(53, 500, .1, alternative_hypothesis = 'greater')\n",
    "print(\"simulation p-value: \", p_value1)\n",
    "\n",
    "p_value2 = binom_test(53, 500, .1, alternative = 'greater')\n",
    "print(\"binom_test p-value: \", p_value2)\n",
    "\n",
    "print('two-sided test:')\n",
    "p_value1 = simulation_binomial_test(42, 500, .1, alternative_hypothesis = 'not_equal')\n",
    "print(\"simulation p-value: \", p_value1)\n",
    "\n",
    "p_value2 = binom_test(42, 500, .1)\n",
    "print(\"binom_test p-value: \", p_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Significance Thresholds\n",
    "Sometimes, when we run a hypothesis test, we simply report a p-value or a confidence interval and give an interpretation (eg., the p-value was 0.05, which means that there is a 5% chance of observing two or fewer heads in 10 coin flips).\n",
    "\n",
    "In other situations, we want to use our p-value to make a decision or answer a yes/no question. For example, suppose that we’re developing a new quiz question at Codecademy and want learners to have a 70% chance of getting the question right (higher would mean the question is too easy, lower would mean the question is too hard). We show our quiz question to a sample of 100 learners and 60 of them get it right. Is this significantly different from our target of 70%? If so, we want to remove the question and try to rewrite it.\n",
    "\n",
    "In order to turn a p-value, which is a probability, into a yes or no answer, data scientists often use a pre-set significance threshold. The significance threshold can be any number between 0 and 1, but a common choice is 0.05. P-values that are less than this threshold are considered “significant”, while larger p-values are considered “not significant”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting a P-Value based on a Significance Threshold\n",
    "Let’s return to the quiz question example from the previous exercise — we want to remove our quiz question from our website if the probability of a correct response is different from 70%. Suppose we collected data from 100 learners and ran a binomial hypothesis test with the following null and alternative hypotheses:\n",
    "\n",
    "- Null: The probability that a learner gets the question correct is 70%.\n",
    "- Alternative: The probability that a learner gets the question correct is not 70%.\n",
    "\n",
    "Assuming that we set a significance threshold of 0.05 for this test:\n",
    "\n",
    "- If the p-value is less than 0.05, the p-value is significant. We will “reject the null hypothesis” and conclude that the probability of a correct answer is significantly different from 70%. This would lead us to re-rewrite the question.\n",
    "\n",
    "- If the p-value is greater than 0.05, the p-value is not significant. We will not be able to reject the null hypothesis, and will conclude that the probability of a correct answer is not significantly different from 70%. This would lead us to leave the question on the site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Types\n",
    "Whenever we run a hypothesis test using a significance threshold, we expose ourselves to making two different kinds of mistakes: type I errors (false positives) and type II errors (false negatives):\n",
    "\n",
    "<img src = 'pic.png'>\n",
    "\n",
    "Consider the quiz question hypothesis test described in the previous exercises:\n",
    "\n",
    "- Null: The probability that a learner answers a question correctly is 70%.\n",
    "- Alternative: The probability that a learner answers a question correctly is not 70%.\n",
    "\n",
    "Suppose, for a moment, that the true probability of a learner answering the question correctly is 70% (if we showed the question to ALL learners, exactly 70% would answer it correctly). This puts us in the first column of the table above (the null hypothesis “is true”). If we run a test and calculate a significant p-value, we will make type I error (also called a false positive because the p-value is falsely significant), leading us to remove the question when we don’t need to.\n",
    "\n",
    "On the other hand, if the true probability of getting the question correct is not 70%, the null hypothesis “is false” (the right-most column of our table). If we run a test and calculate a non-significant p-value, we make a type II error, leading us to leave the question on our site when we should have taken it down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that the average score on a standardized test is 50 points. A researcher wants to know whether students who take this test in an ergonomically designed chair score significantly differently from the general population of test-takers. The researcher randomly assigns 100 students to take the test in an ergonomic chair. Then, the researcher runs a hypothesis test with a significance threshold of 0.05 and the following null and alternative hypotheses:\n",
    "\n",
    "- Null: The mean score for students who take the test in an ergonomic chair is 50 points.\n",
    "- Alternative: The mean score for students who take the test in an ergonomic chair is not 50 points.\n",
    "\n",
    "Suppose that the truth (which the researcher doesn’t know) is: if every student took the test in an ergonomic chair, the average score for all test-takers would be 52 points.\n",
    "\n",
    "Based on their sample of only 100 students, the researcher calculates a p-value of 0.07. In script.py, change the value of outcome to:\n",
    "\n",
    "'correct' if the researcher will come to the correct conclusion based on this test\n",
    "'type one' if the researcher will make a type I error based on this test\n",
    "'type two' if the researcher will make a type II error based on this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662\n"
     ]
    }
   ],
   "source": [
    "# Initialize num_errors\n",
    "false_positives = 0\n",
    "# Set significance threshold value\n",
    "sig_threshold = 0.05\n",
    "\n",
    "# Run binomial tests & record errors\n",
    "for i in range(1000):\n",
    "    sim_sample = np.random.choice(['correct', 'incorrect'], size=100, p=[0.8, 0.2])\n",
    "    num_correct = np.sum(sim_sample == 'correct')\n",
    "    p_val = binom_test(num_correct, 100, .7)\n",
    "    if p_val < sig_threshold:\n",
    "        false_positives += 1\n",
    "\n",
    "# Print proportion of type I errors \n",
    "print(false_positives/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
